## Chapter 4

Supervised Learning

classification problems - learning how to predict the correct label
regression problems - Supervised learning can also be used in situations where the predicted outcome is a number.

Split your data set into two parts: the training data and the test data. We first train the algorithm using only the training data. This gives us a model or a rule that predicts the output based on the input variables.

The accuracy of a predictor learned by machine learning can be quite different in the training data and in separate test data. This is the so-called overfitting phenomenon.  This could make your rule fit the past data perfectly, but it could in fact make it work worse on future test data.
Machine learning methods are especially prone to overfitting because they can try a huge number of different “rules” until one that fits the training data perfectly is found.

Unsupervised Learning
Typical unsupervised learning methods attempt to learn some kind of “structure” underlying the data

Visualization where similar items are placed near each other and dissimilar items further away from each other. 
Clustering where we use the data to identify groups or “clusters” of items that are similar to each other but dissimilar from data in other clusters.
Generative modeling  generative adversarial networks (GANs) -> generating new things from old data.

Nearest neighbor is to relate the class values to similarity or proximity (nearness).
What current recommendation systems use instead of the manually entered metadata, is something called collaborative filtering.

Filter bubbles issue in recommendation systems.

Regression

The basic idea in linear regression is to add up the effects of each of the feature variables to produce the predicted value. The technical term for the adding up process is linear combination.

coefficients or weights
technical term for the starting point is the intercept.

Linear regression -With this kind of simple analysis, we can only identify associations, which can nevertheless be useful for prediction. Application:  prediction of software cost, click rates, box-office revenue etc.
We can turn the linear regression method’s outputs into predictions about labels. The technique for doing this is called logistic regression. Application:  predicting financial risks, in medical studies, and so on.

The factors that affect how good a result:
     machine learning method
     amount of training data
     quality of the data
    complexity/ hardness of the task

Classification error: the fraction of cases where our classifier outputs the wrong class.
